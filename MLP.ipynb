{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6d/dc/464f59597a5a8282585238e6e3a7bb3770c3c1f1dc8ee72bd5be257178ec/tensorflow-1.8.0-cp35-cp35m-manylinux1_x86_64.whl (49.1MB)\n",
      "\u001b[K    100% |████████████████████████████████| 49.1MB 820kB/s \n",
      "\u001b[?25hCollecting gast>=0.2.0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/5c/78/ff794fcae2ce8aa6323e789d1f8b3b7765f601e7702726f430e814822b96/gast-0.2.0.tar.gz\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/8a/48/a76be51647d0eb9f10e2a4511bf3ffb8cc1e6b14e9e4fab46173aa79f981/termcolor-1.1.0.tar.gz\n",
      "Collecting absl-py>=0.1.6 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/90/6b/ba04a9fe6aefa56adafa6b9e0557b959e423c49950527139cb8651b0480b/absl-py-0.2.0.tar.gz (82kB)\n",
      "\u001b[K    100% |████████████████████████████████| 92kB 15.7MB/s \n",
      "\u001b[?25hCollecting tensorboard<1.9.0,>=1.8.0 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/59/a6/0ae6092b7542cfedba6b2a1c9b8dceaf278238c39484f3ba03b03f07803c/tensorboard-1.8.0-py3-none-any.whl (3.1MB)\n",
      "\u001b[K    100% |████████████████████████████████| 3.1MB 1.9MB/s \n",
      "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.5/site-packages (from tensorflow) (0.29.0)\n",
      "Collecting protobuf>=3.4.0 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5b/c3/9b947e301e19bea75dc8c1fd3710eed5d2b31aa13ae13d5e38e891f784cc/protobuf-3.5.2.post1-cp35-cp35m-manylinux1_x86_64.whl (6.4MB)\n",
      "\u001b[K    100% |████████████████████████████████| 6.4MB 7.4MB/s \n",
      "\u001b[?25hCollecting numpy>=1.13.3 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7b/61/11b05cc37ccdaabad89f04dbdc2a02905cf6de6f9b05816dba843beed328/numpy-1.14.3-cp35-cp35m-manylinux1_x86_64.whl (12.1MB)\n",
      "\u001b[K    100% |████████████████████████████████| 12.1MB 5.3MB/s \n",
      "\u001b[?25hCollecting grpcio>=1.8.6 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/33/c8/368aeb6d300ffe03f1703605c097a705500c063f5c0dbf90012b243589ce/grpcio-1.11.0-cp35-cp35m-manylinux1_x86_64.whl (8.8MB)\n",
      "\u001b[K    100% |████████████████████████████████| 8.8MB 7.0MB/s \n",
      "\u001b[?25hCollecting astor>=0.6.0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/b2/91/cc9805f1ff7b49f620136b3a7ca26f6a1be2ed424606804b0fbcf499f712/astor-0.6.2-py2.py3-none-any.whl\n",
      "Requirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.5/site-packages (from tensorflow) (1.10.0)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<1.9.0,>=1.8.0->tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6d/7d/488b90f470b96531a3f5788cf12a93332f543dbab13c423a5e7ce96a0493/Markdown-2.6.11-py2.py3-none-any.whl (78kB)\n",
      "\u001b[K    100% |████████████████████████████████| 81kB 20.7MB/s \n",
      "\u001b[?25hCollecting werkzeug>=0.11.10 (from tensorboard<1.9.0,>=1.8.0->tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/c4/12e3e56473e52375aa29c4764e70d1b8f3efa6682bef8d0aae04fe335243/Werkzeug-0.14.1-py2.py3-none-any.whl (322kB)\n",
      "\u001b[K    100% |████████████████████████████████| 327kB 16.4MB/s \n",
      "\u001b[?25hRequirement already satisfied: bleach==1.5.0 in /opt/conda/lib/python3.5/site-packages (from tensorboard<1.9.0,>=1.8.0->tensorflow) (1.5.0)\n",
      "Collecting html5lib==0.9999999 (from tensorboard<1.9.0,>=1.8.0->tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/ae/bcb60402c60932b32dfaf19bb53870b29eda2cd17551ba5639219fb5ebf9/html5lib-0.9999999.tar.gz (889kB)\n",
      "\u001b[K    100% |████████████████████████████████| 890kB 18.9MB/s \n",
      "\u001b[?25hRequirement already satisfied: setuptools in /opt/conda/lib/python3.5/site-packages/setuptools-23.0.0-py3.5.egg (from protobuf>=3.4.0->tensorflow) (23.0.0)\n",
      "Building wheels for collected packages: gast, termcolor, absl-py, html5lib\n",
      "  Running setup.py bdist_wheel for gast ... \u001b[?25l-\b \b\\\b \bdone\n",
      "\u001b[?25h  Stored in directory: /home/jovyan/.cache/pip/wheels/9a/1f/0e/3cde98113222b853e98fc0a8e9924480a3e25f1b4008cedb4f\n",
      "  Running setup.py bdist_wheel for termcolor ... \u001b[?25l-\b \b\\\b \bdone\n",
      "\u001b[?25h  Stored in directory: /home/jovyan/.cache/pip/wheels/7c/06/54/bc84598ba1daf8f970247f550b175aaaee85f68b4b0c5ab2c6\n",
      "  Running setup.py bdist_wheel for absl-py ... \u001b[?25l-\b \b\\\b \b|\b \bdone\n",
      "\u001b[?25h  Stored in directory: /home/jovyan/.cache/pip/wheels/23/35/1d/48c0a173ca38690dd8dfccfa47ffc750db48f8989ed898455c\n",
      "  Running setup.py bdist_wheel for html5lib ... \u001b[?25l-\b \b\\\b \bdone\n",
      "\u001b[?25h  Stored in directory: /home/jovyan/.cache/pip/wheels/50/ae/f9/d2b189788efcf61d1ee0e36045476735c838898eef1cad6e29\n",
      "Successfully built gast termcolor absl-py html5lib\n",
      "\u001b[31mjupyterhub 0.7.2 requires alembic, which is not installed.\u001b[0m\n",
      "Installing collected packages: gast, termcolor, absl-py, numpy, markdown, werkzeug, protobuf, html5lib, tensorboard, grpcio, astor, tensorflow\n",
      "  Found existing installation: numpy 1.11.3\n",
      "    Uninstalling numpy-1.11.3:\n",
      "      Successfully uninstalled numpy-1.11.3\n",
      "  Found existing installation: html5lib 0.999\n",
      "    Uninstalling html5lib-0.999:\n",
      "      Successfully uninstalled html5lib-0.999\n",
      "Successfully installed absl-py-0.2.0 astor-0.6.2 gast-0.2.0 grpcio-1.11.0 html5lib-0.9999999 markdown-2.6.11 numpy-1.14.3 protobuf-3.5.2.post1 tensorboard-1.8.0 tensorflow-1.8.0 termcolor-1.1.0 werkzeug-0.14.1\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_silver=pd.read_csv(\"Data_silver.csv\")\n",
    "data_gold=pd.read_csv(\"Data_gold.csv\")\n",
    "data_plat=pd.read_csv(\"Data_Plat.csv\")\n",
    "data_diamond=pd.read_csv(\"Data_diamond.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data=data_silver.append([data_gold,data_plat,data_diamond])\n",
    "X=np.array(data.values[:,7:],'double')\n",
    "Y=np.array(data.values[:,1],'double')\n",
    "\n",
    "where_are_NaNs = np.isnan(X)\n",
    "X[where_are_NaNs] = 0\n",
    "\n",
    "Y[Y==100]=1\n",
    "Y[Y==200]=0\n",
    "\n",
    "Y1=Y\n",
    "Y = np.array([Y, -(Y-1)]).T\n",
    "\n",
    "XX, X_TEST, YY, Y_TEST = train_test_split(X, Y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  1.,  0., ...,  1.,  0.,  0.])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=YY\n",
    "y[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "XX_10=XX[:,list(range(0,20))+list(range(58,63))]\n",
    "X_TEST_10=X_TEST[:,list(range(0,20))+list(range(58,63))]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_scaler=StandardScaler()\n",
    "X_scaler.fit(XX)\n",
    "XX_scaled=X_scaler.transform(XX)   \n",
    "X_TEST_scaled=X_scaler.transform(X_TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "?StratifiedKFold.split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5)\n",
    "X=XX_scaled\n",
    "y=YY\n",
    "splits_training_auc =[]\n",
    "splits_test_auc =[]\n",
    "\n",
    "lr_settings=[0.1,0.05,0.01,0.005,0.001]\n",
    "n1_settings=[5,10,15,20,25,30]\n",
    "n2_settings=[5,10,15,20,25,30]\n",
    "\n",
    "#neighbors_settings=range(1,50)\n",
    "\n",
    "#train_auc_3d_pre=np.zeros((5,5,6,6))\n",
    "test_accuracy_3d=np.zeros((5,5,6,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0 0\n",
      "0 0 0 1\n",
      "0 0 0 2\n",
      "0 0 0 3\n",
      "0 0 0 4\n",
      "0 0 0 5\n",
      "0 0 1 0\n",
      "0 0 1 1\n",
      "0 0 1 2\n",
      "0 0 1 3\n",
      "0 0 1 4\n",
      "0 0 1 5\n",
      "0 0 2 0\n",
      "0 0 2 1\n",
      "0 0 2 2\n",
      "0 0 2 3\n",
      "0 0 2 4\n",
      "0 0 2 5\n",
      "0 0 3 0\n",
      "0 0 3 1\n",
      "0 0 3 2\n",
      "0 0 3 3\n",
      "0 0 3 4\n",
      "0 0 3 5\n",
      "0 0 4 0\n",
      "0 0 4 1\n",
      "0 0 4 2\n",
      "0 0 4 3\n",
      "0 0 4 4\n",
      "0 0 4 5\n",
      "0 0 5 0\n",
      "0 0 5 1\n",
      "0 0 5 2\n",
      "0 0 5 3\n",
      "0 0 5 4\n",
      "0 0 5 5\n",
      "0 1 0 0\n",
      "0 1 0 1\n",
      "0 1 0 2\n",
      "0 1 0 3\n",
      "0 1 0 4\n",
      "0 1 0 5\n",
      "0 1 1 0\n",
      "0 1 1 1\n",
      "0 1 1 2\n",
      "0 1 1 3\n",
      "0 1 1 4\n",
      "0 1 1 5\n",
      "0 1 2 0\n",
      "0 1 2 1\n",
      "0 1 2 2\n",
      "0 1 2 3\n",
      "0 1 2 4\n",
      "0 1 2 5\n",
      "0 1 3 0\n",
      "0 1 3 1\n",
      "0 1 3 2\n",
      "0 1 3 3\n",
      "0 1 3 4\n",
      "0 1 3 5\n",
      "0 1 4 0\n",
      "0 1 4 1\n",
      "0 1 4 2\n",
      "0 1 4 3\n",
      "0 1 4 4\n",
      "0 1 4 5\n",
      "0 1 5 0\n",
      "0 1 5 1\n",
      "0 1 5 2\n",
      "0 1 5 3\n",
      "0 1 5 4\n",
      "0 1 5 5\n",
      "0 2 0 0\n",
      "0 2 0 1\n",
      "0 2 0 2\n",
      "0 2 0 3\n",
      "0 2 0 4\n",
      "0 2 0 5\n",
      "0 2 1 0\n",
      "0 2 1 1\n",
      "0 2 1 2\n",
      "0 2 1 3\n",
      "0 2 1 4\n",
      "0 2 1 5\n",
      "0 2 2 0\n",
      "0 2 2 1\n",
      "0 2 2 2\n",
      "0 2 2 3\n",
      "0 2 2 4\n",
      "0 2 2 5\n",
      "0 2 3 0\n",
      "0 2 3 1\n",
      "0 2 3 2\n",
      "0 2 3 3\n",
      "0 2 3 4\n",
      "0 2 3 5\n",
      "0 2 4 0\n",
      "0 2 4 1\n",
      "0 2 4 2\n",
      "0 2 4 3\n",
      "0 2 4 4\n",
      "0 2 4 5\n",
      "0 2 5 0\n",
      "0 2 5 1\n",
      "0 2 5 2\n",
      "0 2 5 3\n",
      "0 2 5 4\n",
      "0 2 5 5\n",
      "0 3 0 0\n",
      "0 3 0 1\n",
      "0 3 0 2\n",
      "0 3 0 3\n",
      "0 3 0 4\n",
      "0 3 0 5\n",
      "0 3 1 0\n",
      "0 3 1 1\n",
      "0 3 1 2\n",
      "0 3 1 3\n",
      "0 3 1 4\n",
      "0 3 1 5\n",
      "0 3 2 0\n",
      "0 3 2 1\n",
      "0 3 2 2\n",
      "0 3 2 3\n",
      "0 3 2 4\n",
      "0 3 2 5\n",
      "0 3 3 0\n",
      "0 3 3 1\n",
      "0 3 3 2\n",
      "0 3 3 3\n",
      "0 3 3 4\n",
      "0 3 3 5\n",
      "0 3 4 0\n",
      "0 3 4 1\n",
      "0 3 4 2\n",
      "0 3 4 3\n",
      "0 3 4 4\n",
      "0 3 4 5\n",
      "0 3 5 0\n",
      "0 3 5 1\n",
      "0 3 5 2\n",
      "0 3 5 3\n",
      "0 3 5 4\n",
      "0 3 5 5\n",
      "0 4 0 0\n",
      "0 4 0 1\n",
      "0 4 0 2\n",
      "0 4 0 3\n",
      "0 4 0 4\n",
      "0 4 0 5\n",
      "0 4 1 0\n",
      "0 4 1 1\n",
      "0 4 1 2\n",
      "0 4 1 3\n",
      "0 4 1 4\n",
      "0 4 1 5\n",
      "0 4 2 0\n",
      "0 4 2 1\n",
      "0 4 2 2\n",
      "0 4 2 3\n",
      "0 4 2 4\n",
      "0 4 2 5\n",
      "0 4 3 0\n",
      "0 4 3 1\n",
      "0 4 3 2\n",
      "0 4 3 3\n",
      "0 4 3 4\n",
      "0 4 3 5\n",
      "0 4 4 0\n",
      "0 4 4 1\n",
      "0 4 4 2\n",
      "0 4 4 3\n",
      "0 4 4 4\n",
      "0 4 4 5\n",
      "0 4 5 0\n",
      "0 4 5 1\n",
      "0 4 5 2\n",
      "0 4 5 3\n",
      "0 4 5 4\n",
      "0 4 5 5\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Shape must be rank 1 but is rank 2 for 'strided_slice_1' (op: 'StridedSlice') with input shapes: [?,2], [1,2512], [1,2512], [1].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1566\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1567\u001b[0;31m     \u001b[0mc_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1568\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Shape must be rank 1 but is rank 2 for 'strided_slice_1' (op: 'StridedSlice') with input shapes: [?,2], [1,2512], [1,2512], [1].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-109-24dafb13539b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtrain_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mskf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mtraining_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_slice_helper\u001b[0;34m(tensor, slice_spec, var)\u001b[0m\n\u001b[1;32m    595\u001b[0m         \u001b[0mellipsis_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mellipsis_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m         \u001b[0mvar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m         name=name)\n\u001b[0m\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mstrided_slice\u001b[0;34m(input_, begin, end, strides, begin_mask, end_mask, ellipsis_mask, new_axis_mask, shrink_axis_mask, var, name)\u001b[0m\n\u001b[1;32m    761\u001b[0m       \u001b[0mellipsis_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mellipsis_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m       \u001b[0mnew_axis_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_axis_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 763\u001b[0;31m       shrink_axis_mask=shrink_axis_mask)\n\u001b[0m\u001b[1;32m    764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m   \u001b[0mparent_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mstrided_slice\u001b[0;34m(input, begin, end, strides, begin_mask, end_mask, ellipsis_mask, new_axis_mask, shrink_axis_mask, name)\u001b[0m\n\u001b[1;32m   8146\u001b[0m         \u001b[0mbegin_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbegin_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mend_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mellipsis_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mellipsis_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8147\u001b[0m         \u001b[0mnew_axis_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_axis_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshrink_axis_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshrink_axis_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 8148\u001b[0;31m         name=name)\n\u001b[0m\u001b[1;32m   8149\u001b[0m     \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8150\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    785\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    788\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   3390\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3391\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3392\u001b[0;31m           op_def=op_def)\n\u001b[0m\u001b[1;32m   3393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3394\u001b[0m       \u001b[0;31m# Note: shapes are lazily computed with the C API enabled.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   1732\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[1;32m   1733\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[0;32m-> 1734\u001b[0;31m                                 control_input_ops)\n\u001b[0m\u001b[1;32m   1735\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1736\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1568\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1569\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1570\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1572\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shape must be rank 1 but is rank 2 for 'strided_slice_1' (op: 'StridedSlice') with input shapes: [?,2], [1,2512], [1,2512], [1]."
     ]
    }
   ],
   "source": [
    "m=0\n",
    "for train_index, test_index in skf.split(X, y[:,0]):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index] \n",
    "    training_epochs = 100\n",
    "    batch_size = 100\n",
    "    n_input = 63 # Number of feature\n",
    "    n_classes = 2 # Number of classes to predict\n",
    "    j=0\n",
    "    for lr in lr_settings:\n",
    "        learning_rate = lr\n",
    "        k=0\n",
    "        for n1 in n1_settings:\n",
    "            n_hidden_1=n1\n",
    "            l=0\n",
    "            for n2 in n2_settings:\n",
    "                n_hidden_2 = n2\n",
    "\n",
    "                # tf Graph input\n",
    "                x = tf.placeholder(\"float\", [None, n_input])\n",
    "                y = tf.placeholder(\"float\", [None, n_classes])\n",
    "\n",
    "                # Create model\n",
    "                def multilayer_perceptron(x, weights, biases):\n",
    "                    # Hidden layer with RELU activation\n",
    "                    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
    "                    layer_1 = tf.nn.relu(layer_1)\n",
    "                    # Hidden layer with RELU activation\n",
    "                    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    "                    layer_2 = tf.nn.relu(layer_2)\n",
    "                    # Output layer with linear activation\n",
    "                    out_layer = tf.matmul(layer_2, weights['out']) + biases['out']\n",
    "                    return out_layer\n",
    "\n",
    "                # Store layers weight & bias\n",
    "                weights = {\n",
    "                    'h1': tf.Variable(tf.random_normal([n_input, n_hidden_1])),\n",
    "                    'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "                    'out': tf.Variable(tf.random_normal([n_hidden_2, n_classes]))\n",
    "                }\n",
    "\n",
    "                biases = {\n",
    "                    'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "                    'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "                    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "                }\n",
    "\n",
    "                # Construct model\n",
    "                pred = multilayer_perceptron(x, weights, biases)\n",
    "\n",
    "                # Define loss and optimizer\n",
    "                cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "                optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "                # Initializing the variables\n",
    "                init = tf.global_variables_initializer()\n",
    "                # Launch the graph\n",
    "\n",
    "                with tf.Session() as sess:\n",
    "                    sess.run(init)\n",
    "                    # Training cycle\n",
    "                    for epoch in range(training_epochs):\n",
    "                        avg_cost = 0.\n",
    "                        total_batch = int(len(X)/batch_size)\n",
    "                        X_batches = np.array_split(X_train, total_batch)\n",
    "                        Y_batches = np.array_split(y_train, total_batch)\n",
    "                        # Loop over all batches\n",
    "                        for i in range(total_batch):\n",
    "                            batch_x, batch_y = X_batches[i], Y_batches[i]\n",
    "                            # Run optimization op (backprop) and cost op (to get loss value)\n",
    "                            _, c = sess.run([optimizer, cost], feed_dict={x: batch_x,\n",
    "                                                                          y: batch_y})\n",
    "                            # Compute average loss\n",
    "                            avg_cost += c / total_batch\n",
    "                        # Display logs per epoch step\n",
    "                        #if epoch % display_step == 0:\n",
    "                        #    print(\"Epoch:\", '%04d' % (epoch+1), \"cost=\", \"{:.9f}\".format(avg_cost))\n",
    "                    #print(\"Optimization Finished!\")\n",
    "\n",
    "                    # Test model\n",
    "                    correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "                    # Calculate accuracy\n",
    "                    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "                    print(m,j,k,l)\n",
    "                    test_accuracy_3d[m,j,k,l]=accuracy.eval({x: X_test, y: y_test})\n",
    "                    #global result \n",
    "                    #result = tf.argmax(pred, 1).eval({x: X_TEST_scaled, y: Y_TEST})\n",
    "                l=l+1\n",
    "            k=k+1\n",
    "        j=j+1\n",
    "    m=m+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full_test=test_accuracy_3d[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.97770703,  0.9824841 ,  0.98407644,  0.94108278,  0.9824841 ,\n",
       "          0.97611463],\n",
       "        [ 0.90605098,  0.92993629,  0.97292995,  0.94426751,  0.97452229,\n",
       "          0.97452229],\n",
       "        [ 0.96496814,  0.96337581,  0.88375795,  0.97292995,  0.97292995,\n",
       "          0.97452229],\n",
       "        [ 0.6687898 ,  0.97611463,  0.96974522,  0.97133756,  0.97929937,\n",
       "          0.96974522],\n",
       "        [ 0.97452229,  0.67993629,  0.91242039,  0.97611463,  0.97929937,\n",
       "          0.97611463],\n",
       "        [ 0.55254775,  0.79936308,  0.97452229,  0.70700639,  0.96815288,\n",
       "          0.95700639]],\n",
       "\n",
       "       [[ 0.97452229,  0.97133756,  0.97452229,  0.98726118,  0.97452229,\n",
       "          0.97929937],\n",
       "        [ 0.97292995,  0.98407644,  0.96656048,  0.97292995,  0.96178347,\n",
       "          0.96496814],\n",
       "        [ 0.97452229,  0.96974522,  0.97770703,  0.95859873,  0.96974522,\n",
       "          0.96974522],\n",
       "        [ 0.9808917 ,  0.96974522,  0.97611463,  0.97452229,  0.97452229,\n",
       "          0.96496814],\n",
       "        [ 0.97452229,  0.96815288,  0.96974522,  0.97292995,  0.97611463,\n",
       "          0.97770703],\n",
       "        [ 0.97452229,  0.96815288,  0.96974522,  0.96656048,  0.96815288,\n",
       "          0.96337581]],\n",
       "\n",
       "       [[ 0.96337581,  0.97929937,  0.96815288,  0.96496814,  0.96815288,\n",
       "          0.96019107],\n",
       "        [ 0.96019107,  0.97292995,  0.96178347,  0.95222932,  0.955414  ,\n",
       "          0.97929937],\n",
       "        [ 0.96815288,  0.96178347,  0.95700639,  0.95859873,  0.955414  ,\n",
       "          0.95382166],\n",
       "        [ 0.96178347,  0.96974522,  0.95700639,  0.94904459,  0.95859873,\n",
       "          0.95859873],\n",
       "        [ 0.96974522,  0.95382166,  0.94267517,  0.955414  ,  0.93949044,\n",
       "          0.94904459],\n",
       "        [ 0.96815288,  0.96496814,  0.955414  ,  0.94426751,  0.95859873,\n",
       "          0.94426751]],\n",
       "\n",
       "       [[ 0.97611463,  0.97133756,  0.95859873,  0.94904459,  0.94904459,\n",
       "          0.94585985],\n",
       "        [ 0.95859873,  0.94904459,  0.93949044,  0.955414  ,  0.94267517,\n",
       "          0.94267517],\n",
       "        [ 0.955414  ,  0.95859873,  0.96496814,  0.94745225,  0.96019107,\n",
       "          0.93630576],\n",
       "        [ 0.96337581,  0.95222932,  0.95859873,  0.94745225,  0.94745225,\n",
       "          0.93949044],\n",
       "        [ 0.97133756,  0.955414  ,  0.94904459,  0.96178347,  0.95382166,\n",
       "          0.94745225],\n",
       "        [ 0.96019107,  0.95222932,  0.94585985,  0.95063692,  0.94585985,\n",
       "          0.93471336]],\n",
       "\n",
       "       [[ 0.94904459,  0.96178347,  0.93312103,  0.92356688,  0.93630576,\n",
       "          0.94426751],\n",
       "        [ 0.95063692,  0.94585985,  0.92515922,  0.9378981 ,  0.94904459,\n",
       "          0.94745225],\n",
       "        [ 0.93949044,  0.95222932,  0.94585985,  0.93630576,  0.95063692,\n",
       "          0.9378981 ],\n",
       "        [ 0.95222932,  0.95222932,  0.92038214,  0.93630576,  0.955414  ,\n",
       "          0.93152869],\n",
       "        [ 0.96496814,  0.96019107,  0.95382166,  0.93630576,  0.94108278,\n",
       "          0.955414  ],\n",
       "        [ 0.96178347,  0.94585985,  0.95222932,  0.94904459,  0.95222932,\n",
       "          0.94904459]]])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 6, 6)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lr setting\n",
    "np.argmax(np.mean(full_test,axis=(1,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr=0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.96358811,  0.95504247,  0.95642251,  0.94957537,  0.94994692,\n",
       "        0.93014862])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#n1 settings\n",
    "np.argmax(np.mean(full_test,axis=(0,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n1 settings 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#n2 settings\n",
    "np.argmax(np.mean(full_test,axis=(0,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n2 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "XX_10=XX[:,list(range(0,20))+list(range(58,63))]\n",
    "X_TEST_10=X_TEST[:,list(range(0,20))+list(range(58,63))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_scaler=StandardScaler()\n",
    "X_scaler.fit(XX_10)\n",
    "XX_scaled=X_scaler.transform(XX_10)   \n",
    "X_TEST_scaled=X_scaler.transform(X_TEST_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5)\n",
    "X=XX_scaled\n",
    "y=YY\n",
    "splits_training_auc =[]\n",
    "splits_test_auc =[]\n",
    "\n",
    "lr_settings=[0.05,0.01,0.005,0.001]\n",
    "n1_settings=[5,10,15,20]\n",
    "n2_settings=[5,10,15,20]\n",
    "\n",
    "#neighbors_settings=range(1,50)\n",
    "\n",
    "#train_auc_3d_pre=np.zeros((5,5,6,6))\n",
    "test_accuracy_3d_10=np.zeros((5,4,4,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data=data_silver.append([data_gold,data_plat,data_diamond])\n",
    "X=np.array(data.values[:,7:],'double')\n",
    "Y=np.array(data.values[:,1],'double')\n",
    "\n",
    "where_are_NaNs = np.isnan(X)\n",
    "X[where_are_NaNs] = 0\n",
    "\n",
    "Y[Y==100]=1\n",
    "Y[Y==200]=0\n",
    "\n",
    "Y1=Y\n",
    "Y = np.array([Y, -(Y-1)]).T\n",
    "\n",
    "XX, X_TEST, YY, Y_TEST = train_test_split(X, Y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_epochs = 100\n",
    "batch_size = 100\n",
    "n_input = 25 # Number of feature\n",
    "n_classes = 2 # Number of classes to predict\n",
    "learning_rate = 0.01\n",
    "\n",
    "n_hidden_1=n1\n",
    "n_hidden_2 = n2\n",
    "\n",
    "# tf Graph input\n",
    "x = tf.placeholder(\"float\", [None, n_input])\n",
    "y = tf.placeholder(\"float\", [None, n_classes])\n",
    "\n",
    "# Create model\n",
    "def multilayer_perceptron(x, weights, biases):\n",
    "    # Hidden layer with RELU activation\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "    # Hidden layer with RELU activation\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    "    layer_2 = tf.nn.relu(layer_2)\n",
    "    # Output layer with linear activation\n",
    "    out_layer = tf.matmul(layer_2, weights['out']) + biases['out']\n",
    "    return out_layer\n",
    "\n",
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    'h1': tf.Variable(tf.random_normal([n_input, n_hidden_1])),\n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_2, n_classes]))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}\n",
    "\n",
    "# Construct model\n",
    "pred = multilayer_perceptron(x, weights, biases)\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()\n",
    "# Launch the graph\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    # Training cycle\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0.\n",
    "        total_batch = int(len(X)/batch_size)\n",
    "        X_batches = np.array_split(XX_scaled, total_batch)\n",
    "        Y_batches = np.array_split(YY, total_batch)\n",
    "        # Loop over all batches\n",
    "        for i in range(total_batch):\n",
    "            batch_x, batch_y = X_batches[i], Y_batches[i]\n",
    "            # Run optimization op (backprop) and cost op (to get loss value)\n",
    "            _, c = sess.run([optimizer, cost], feed_dict={x: batch_x,\n",
    "                                                          y: batch_y})\n",
    "            # Compute average loss\n",
    "            avg_cost += c / total_batch\n",
    "        # Display logs per epoch step\n",
    "        #if epoch % display_step == 0:\n",
    "        #    print(\"Epoch:\", '%04d' % (epoch+1), \"cost=\", \"{:.9f}\".format(avg_cost))\n",
    "    #print(\"Optimization Finished!\")\n",
    "\n",
    "    # Test model\n",
    "    correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "    # Calculate accuracy\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    print(m,j,k,l)\n",
    "    test_accuracy_3d_10[m,j,k,l]=accuracy.eval({x: X_TEST, y: Y_TEST})\n",
    "    #global result \n",
    "    #result = tf.argmax(pred, 1).eval({x: X_TEST_scaled, y: Y_TEST})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 0.55254775,  0.6687898 ,  0.54936308,  0.67197454,  0.66560507,\n",
       "           0.69267517],\n",
       "         [ 0.67834395,  0.55573249,  0.63535035,  0.66242039,  0.66401273,\n",
       "           0.63216561],\n",
       "         [ 0.66719747,  0.64490443,  0.66719747,  0.67038214,  0.63694268,\n",
       "           0.65605098],\n",
       "         [ 0.63375795,  0.56050956,  0.63057327,  0.60350317,  0.61624205,\n",
       "           0.56847131],\n",
       "         [ 0.55414015,  0.63535035,  0.64968151,  0.60828024,  0.55732483,\n",
       "           0.65764332],\n",
       "         [ 0.55254775,  0.55095541,  0.58280253,  0.5812102 ,  0.56369424,\n",
       "           0.54936308]],\n",
       "\n",
       "        [[ 0.69745225,  0.67197454,  0.68312103,  0.6878981 ,  0.68471336,\n",
       "           0.67356688],\n",
       "         [ 0.67197454,  0.65127391,  0.66242039,  0.65764332,  0.64968151,\n",
       "           0.66082805],\n",
       "         [ 0.66082805,  0.6433121 ,  0.64012736,  0.64490443,  0.65286624,\n",
       "           0.66560507],\n",
       "         [ 0.66242039,  0.68471336,  0.64171976,  0.62898088,  0.66082805,\n",
       "           0.64808917],\n",
       "         [ 0.6433121 ,  0.6257962 ,  0.64171976,  0.63375795,  0.64808917,\n",
       "           0.63216561],\n",
       "         [ 0.65923566,  0.66560507,  0.61464965,  0.66560507,  0.66560507,\n",
       "           0.63057327]],\n",
       "\n",
       "        [[ 0.67993629,  0.69108278,  0.6878981 ,  0.65764332,  0.64490443,\n",
       "           0.66242039],\n",
       "         [ 0.66082805,  0.66242039,  0.64490443,  0.61783439,  0.63853502,\n",
       "           0.65127391],\n",
       "         [ 0.67515922,  0.67515922,  0.64171976,  0.64808917,  0.61464965,\n",
       "           0.62101912],\n",
       "         [ 0.67515922,  0.65605098,  0.65605098,  0.63216561,  0.6242038 ,\n",
       "           0.61146498],\n",
       "         [ 0.68312103,  0.65445858,  0.6242038 ,  0.66242039,  0.6433121 ,\n",
       "           0.61146498],\n",
       "         [ 0.65286624,  0.65764332,  0.63057327,  0.63535035,  0.64968151,\n",
       "           0.61783439]],\n",
       "\n",
       "        [[ 0.68630576,  0.65923566,  0.67675161,  0.66082805,  0.68630576,\n",
       "           0.63694268],\n",
       "         [ 0.67356688,  0.68312103,  0.66082805,  0.64012736,  0.6687898 ,\n",
       "           0.67197454],\n",
       "         [ 0.66560507,  0.67356688,  0.67356688,  0.61942673,  0.63535035,\n",
       "           0.61942673],\n",
       "         [ 0.66401273,  0.65764332,  0.64012736,  0.63375795,  0.59872609,\n",
       "           0.63853502],\n",
       "         [ 0.66560507,  0.67834395,  0.66719747,  0.62261146,  0.63535035,\n",
       "           0.6433121 ],\n",
       "         [ 0.66401273,  0.64808917,  0.64490443,  0.63375795,  0.64490443,\n",
       "           0.64968151]],\n",
       "\n",
       "        [[ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ]]],\n",
       "\n",
       "\n",
       "       [[[ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ]],\n",
       "\n",
       "        [[ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ]],\n",
       "\n",
       "        [[ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ]],\n",
       "\n",
       "        [[ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ]],\n",
       "\n",
       "        [[ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ]]],\n",
       "\n",
       "\n",
       "       [[[ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ]],\n",
       "\n",
       "        [[ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ]],\n",
       "\n",
       "        [[ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ]],\n",
       "\n",
       "        [[ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ]],\n",
       "\n",
       "        [[ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ]]],\n",
       "\n",
       "\n",
       "       [[[ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ]],\n",
       "\n",
       "        [[ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ]],\n",
       "\n",
       "        [[ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ]],\n",
       "\n",
       "        [[ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ]],\n",
       "\n",
       "        [[ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ]]],\n",
       "\n",
       "\n",
       "       [[[ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ]],\n",
       "\n",
       "        [[ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ]],\n",
       "\n",
       "        [[ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ]],\n",
       "\n",
       "        [[ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ]],\n",
       "\n",
       "        [[ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ]]]])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy_3d_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
